{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y! Watchlist  \n",
    "\n",
    "* most-active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "baseUrl = \"https://finance.yahoo.com/most-active/\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:101.0) Gecko/20100101 Firefox/101.0', \"cookie\": \"CONSENT=YES+cb.20230531-04-p0.en+FX+908\"}\n",
    "\n",
    "response = requests.get(baseUrl , headers=headers )\n",
    "\n",
    "if response.status_code != 200:\n",
    "\tprint(\"Error fetching page\")\n",
    "\texit()\n",
    "else:\n",
    "\n",
    "\tcontent = response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUT FULL PAGE\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The title tag of the page\n",
    "print(soup.title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97 links in this page\n"
     ]
    }
   ],
   "source": [
    "# All links in the page\n",
    "\n",
    "nb_links = len(soup.find_all('a'))\n",
    "print(f\"There are {nb_links} links in this page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finxter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home\n",
      "Mail\n",
      "News\n",
      "Finance\n",
      "Sports\n",
      "Entertainment\n",
      "Search\n",
      "Mobile\n",
      "More...\n",
      "Yahoo Finance\n",
      "Skip to Navigation\n",
      "Skip to Main Content\n",
      "Skip to Related Content\n",
      "Sign in\n",
      "Mail\n",
      "Sign in\n",
      "Finance Home\n",
      "Watchlists\n",
      "My Portfolio\n",
      "Crypto\n",
      "Yahoo Finance Plus\n",
      "News\n",
      "Screeners\n",
      "Markets\n",
      "Videos\n",
      "Personal Finance\n",
      "Industries\n",
      "Contact Us\n",
      "Calendars\n",
      "Trending Tickers\n",
      "Stocks: Most Actives\n",
      "Stocks: Gainers\n",
      "Stocks: Losers\n",
      "Top ETFs\n",
      "Futures\n",
      "World Indices\n",
      "Currencies\n",
      "Top Mutual Funds\n",
      "Options: Highest Open Interest\n",
      "Options: Highest Implied Volatility\n",
      "US Treasury Bonds Rates\n",
      "Currency Converter\n",
      "S&P Futures\n",
      "\n",
      "Dow Futures\n",
      "\n",
      "Nasdaq Futures\n",
      "\n",
      "Russell 2000 Futures\n",
      "\n",
      "Crude Oil\n",
      "\n",
      "Gold\n",
      "\n",
      "All Screeners\n",
      "Results List\n",
      "Heatmap View\n",
      "NIO\n",
      "TSLA\n",
      "BAC\n",
      "AAPL\n",
      "XPEV\n",
      "AMZN\n",
      "TLRY\n",
      "ITUB\n",
      "CCL\n",
      "NU\n",
      "LU\n",
      "AMD\n",
      "CS\n",
      "F\n",
      "RLX\n",
      "META\n",
      "NVDA\n",
      "INTC\n",
      "IQ\n",
      "CMCSA\n",
      "WFC\n",
      "PLTR\n",
      "SWN\n",
      "BABA\n",
      "BILI\n",
      "Meet the 29-year-old teacher with four degrees who wants to join the Great Resignation because she’s tired of working ‘way above’ her paycheck\n",
      "La subvención solar arrasa en España\n",
      "Anuncio\n",
      "The Eco Experts\n",
      "Railway strike: Paid sick leave doesn’t affect investors ‘over the long term,’ ESG investor says\n",
      "Data Disclaimer\n",
      "Help\n",
      "Suggestions\n",
      "Privacy\n",
      "About Our Ads\n",
      "Terms\n",
      "Sitemap\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GET ALL Text from the LINKS\n",
    "\n",
    "items = [item.text.strip() for item in soup.select('a') ]\n",
    "\n",
    "for i in items:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   REMOVE NON LINK TEXT\n",
    "\n",
    "test_list = [item.text.strip() for item in soup.select('a') ]\n",
    "\n",
    "test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Tuples : ['', '', '', '', '', '', 'NIO', 'TSLA', 'BAC', 'AAPL', 'XPEV', 'AMZN', 'TLRY', 'ITUB', 'CCL', 'NU', 'LU', 'AMD', 'CS', 'F', 'RLX', 'META', 'NVDA', 'INTC', 'IQ', 'CMCSA', 'WFC', 'PLTR', 'SWN', 'BABA', 'BILI', '', '', '']\n",
      "['NIO', 'TSLA', 'BAC', 'AAPL', 'XPEV', 'AMZN', 'TLRY', 'ITUB', 'CCL', 'NU', 'LU', 'AMD', 'CS', 'F', 'RLX', 'META', 'NVDA', 'INTC', 'IQ', 'CMCSA', 'WFC', 'PLTR', 'SWN', 'BABA', 'BILI']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  FILTER FOR CAPS ONLY\n",
    "\n",
    "lst_Mactive = []\n",
    "for sub in items:\n",
    "    upperChars = True\n",
    "    for ele in sub:\n",
    " \n",
    "        # checking for uppercase\n",
    "        if not ele.isupper():\n",
    "            upperChars = False\n",
    "            break\n",
    "    if upperChars:\n",
    "        lst_Mactive.append(sub)\n",
    " \n",
    "# printing results\n",
    "print(\"Filtered Tuples : \" + str(lst_Mactive))\n",
    "\n",
    "# remove blanks\n",
    "#   Python 3 returns an iterator from filter, so should be wrapped in a call to list()\n",
    "\n",
    "lst_Mactive = list(filter(None, lst_Mactive))\n",
    "print(lst_Mactive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method #2 : Using list comprehension + all() + isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FILTER FOR CAPS ONLY\n",
    "#  uppercase characters Tuples\n",
    "#  Using list comprehension + all() + isupper()\n",
    " \n",
    "# initializing list\n",
    "test_list = [item.text.strip() for item in soup.select('a') ]\n",
    " \n",
    "# all() returns true only when all strings are uppercase\n",
    "upperChars = [sub for sub in test_list if all(ele.isupper() for ele in sub)]\n",
    "\n",
    "# remove blanks\n",
    "lst_Mactive = list(filter(None, lst_Mactive))\n",
    "\n",
    "# printing results\n",
    "print(\"Filtered Y! Most Active Watchlist : \\n\" + str(lst_Mactive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYSE ONLY \n",
    " \n",
    "* list index ending\n",
    "* filter out all Pinks\n",
    "* remove excess text spaces / lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append END while not END to RES_LST\n",
    "\n",
    "tkr = '' \n",
    "\n",
    "def txtStripper(dcf):\n",
    "    dcf = dcf.replace('\\n', '')\n",
    "    dcf = dcf.strip()\n",
    "    print((tkr), ':',  (dcf))\n",
    "\n",
    "lst_Mactive.append('END')\n",
    "\n",
    "while tkr != 'END':\n",
    "    try:\n",
    "        for l in lst_Mactive:\n",
    "                    \n",
    "                        tkr = l\n",
    "                        baseUrl = 'https://site.financialmodelingprep.com/discounted-cash-flow-model/{}'\n",
    "                        url = baseUrl.format(str(tkr))\n",
    "                        response = urllib.request.urlopen(url)\n",
    "                        url_contents = response.read()\n",
    "\n",
    "                        soup = BeautifulSoup(url_contents, \"html.parser\")\n",
    "                        dcf = soup.find(\"div\", {\"class\": \"global-button2\"}).text\n",
    "\n",
    "                        txtStripper(dcf)\n",
    "\n",
    "    except AttributeError:\n",
    "        print('No' , (tkr) )\n",
    "        lst_Mactive.remove(tkr)\n",
    "        print('Ammended tkr: ' , lst_Mactive)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store list to pass to next file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%store lst_Mactive\n",
    "lst_Mactive \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72cc61c9694d467099ef54652d088522f74d141b3af5eb71a7e52280ce52fefc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
